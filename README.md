# Interpretability

This repository contains an example case for applying interpretability and feature selection techniques to machine learning models.

Please see blog post for additional context: [How Interpretability Can Improve Machine Learning Performance](https://medium.com/@iszpakowski/how-interpretability-can-improve-machine-learning-model-performance-925543432f7f)

## Resources & References

"Bank Marketing Data Set," UC Irvine, https://archive.ics.uci.edu/ml/datasets/Bank+Marketing.

Christopher Molnar, "Interpretable Machine Learning: A Guide for Making Black Box Models Explainable," 2022, https://christophm.github.io/interpretable-ml-book/.

Scott Lundberg, "SHAP", https://github.com/slundberg/shap.

"Partial Dependence and Individual Conditional Expectation plots", Sci-kit Learn User Guide, https://scikit-learn.org/stable/modules/partial_dependence.html.

Seldon Technologies Ltd, "Alibi Documentation," Release 0.8.1 dev, October 12, 2022, https://readthedocs.org/projects/alibi/downloads/pdf/latest/.

Dana Jomar, "PyALE," https://github.com/DanaJomar/PyALE.

Seppe van den Broucke, "Discovering Interaction Effects in Ensemble Models," February 22, 2019, https://blog.macuyiko.com/post/2019/discovering-interaction-effects-in-ensemble-models.html.

Seppe van den Broucke, "Revisiting Discovery of Interaction Effects," January 3, 2021, https://blog.macuyiko.com/post/2021/revisiting-discovery-of-interaction-effects.html.

Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin, "'Why Should I Trust You?' Explaining the Predictions of Any Classifier," August 9, 2016, https://arxiv.org/pdf/1602.04938.pdf.
